{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10172100163 宫泽正 NLP作业4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作业四 文本纠错  \n",
    "任务描述：给出三个文件，词典库vocab.txt（任何不在词典中出现的词都认为是拼写错误），spell-errors.txt（给出正确单词与常见的拼写错误）与测试数据testdata.txt（1000个存在拼写错误的句子），利用bigram语言模型与Noisy Channel Model进行文本纠错训练。  \n",
    "步骤（每一步注释标注）：  \n",
    "一、读取词典库vocab.txt；  \n",
    "二、对于词库里没有的词，取编辑距离为1和2，生成候选词集合；  \n",
    "三、读取spell-errors.txt，计算概率p(错误的单词|正确的单词)；  \n",
    "四、选用nltk语料库movie_reviews，构建bigram语言模型；  \n",
    "五、读取testdata.txt，找出拼错词，生成候选词，并计算每个候选词的概率；  \n",
    "六、选出概率最高的候选词，作为修改词。  \n",
    "注：为便于计算，可采用似然对数，将概率乘积转化为求和。注意平滑。  \n",
    "输出：对每个句子，输出句子编号，拼错词，修改词（若没有则输出False），候选词列表及概率。最后输出总拼错词数。  \n",
    "例如：  \n",
    "第1句：  \n",
    "protectionst, protectionist  \n",
    "{'protectionist': -30.484951869432177}  \n",
    "第2句：  \n",
    "Tkyo's, False  \n",
    "第3句：  \n",
    "retaliation, retaliation  \n",
    "{'retaliation': -30.97301670912914}  \n",
    "Japan's, Japan  \n",
    "{'Japan': -30.748299246173307, 'Japanese': -30.748299246173307}  \n",
    "……  \n",
    "Total mistakes: 1351  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews as mr\n",
    "import Levenshtein\n",
    "import math\n",
    "from nltk import FreqDist\n",
    "from nltk.collocations import BigramCollocationFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取所有数据\n",
    "pathV =\"D:/ECNU2021/自然语言处理/作业4/vocab.txt\"\n",
    "pathTD = \"D:/ECNU2021/自然语言处理/作业4/testdata.txt\"\n",
    "pathSE = \"D:/ECNU2021/自然语言处理/作业4/spell-errors.txt\"\n",
    "vocab = []\n",
    "testdata = []\n",
    "spellerrors = {}\n",
    "with open(pathV,'r') as f:\n",
    "    while True:\n",
    "        temp = f.readline()\n",
    "        if not temp:\n",
    "            break\n",
    "        vocab.append(temp[0:-1])\n",
    "with open(pathTD,'r') as f:\n",
    "    while True:\n",
    "        temp = f.readline()\n",
    "        if not temp:\n",
    "            break\n",
    "        spl = temp.strip().split('\\t')\n",
    "        testdata.append((spl[0],spl[1],spl[2][0:-1]))\n",
    "#spellerror中有一些是*2，*3，这里要把它去掉。\n",
    "with open(pathSE,'r') as f:\n",
    "    while True:\n",
    "        temp = f.readline()\n",
    "        if not temp:\n",
    "            break\n",
    "        spl=temp.strip().split(':')\n",
    "        words = spl[1].strip().split(',')\n",
    "        new_words = []\n",
    "        for w in words:\n",
    "            if w[0]==' ':\n",
    "                w = w[1:]\n",
    "            if len(w)>2 and w[-2]=='*':\n",
    "                w=w[0:-2]\n",
    "            new_words.append(w)\n",
    "        spellerrors[spl[0]]=new_words\n",
    "#print(spellerrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成候选词集合函数，利用Levenshtein库\n",
    "def candidate(word):\n",
    "    ret = []\n",
    "    for w in vocab:\n",
    "        if Levenshtein.distance(word,w)<=2:\n",
    "            ret.append(w)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram的建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建bigram语言模型\n",
    "f = mr.fileids()\n",
    "bigram = []\n",
    "for dat in f:\n",
    "    bigram.append(mr.words(dat))\n",
    "co = []\n",
    "for dat in bigram:\n",
    "    for i in dat:\n",
    "        co.append(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4901\n"
     ]
    }
   ],
   "source": [
    "finder = BigramCollocationFinder.from_words(co)\n",
    "freq = FreqDist(co)\n",
    "print(freq[\"have\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
